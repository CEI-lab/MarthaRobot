{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dt_apriltags as atag\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create detector\n",
    "detector = atag.Detector(families=\"tagStandard41h12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_images = [\n",
    "    # \"testimages/cal1.jpg\",\n",
    "    \"testimages/cal2.jpg\",\n",
    "    \"testimages/cal3.jpg\",\n",
    "    \"testimages/cal4.jpg\",\n",
    "    \"testimages/cal5.jpg\",\n",
    "    \"testimages/cal6.jpg\",\n",
    "    \"testimages/cal7.jpg\",\n",
    "    \"testimages/cal8.jpg\",\n",
    "    \"testimages/cal9.jpg\",\n",
    "    \"testimages/cal10.jpg\",\n",
    "    \"testimages/cal11.jpg\",\n",
    "    \"testimages/cal12.jpg\",\n",
    "    \"testimages/cal13.jpg\",\n",
    "    \"testimages/cal14.jpg\",\n",
    "    \"testimages/cal15.jpg\",\n",
    "    \"testimages/cal16.jpg\",\n",
    "]\n",
    "\n",
    "calibration_grid = (9, 5)\n",
    "calibration_sep = (0.25, 0.5)\n",
    "calibration_size = 0.75\n",
    "calibration_offset = (\n",
    "    calibration_sep[0] + calibration_size,\n",
    "    calibration_sep[1] + calibration_size,\n",
    ")\n",
    "pixel_per_tag = 9\n",
    "pixel_width = calibration_size / pixel_per_tag\n",
    "tag_count = calibration_grid[0] * calibration_grid[1]\n",
    "tag_corners = [\n",
    "    [2 * pixel_width, 2 * pixel_width],\n",
    "    [2 * pixel_width, 7 * pixel_width],\n",
    "    [7 * pixel_width, 7 * pixel_width],\n",
    "    [7 * pixel_width, 2 * pixel_width],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "truepoints = []\n",
    "for x in range(calibration_grid[0]):\n",
    "    for y in range(calibration_grid[1]):\n",
    "        origin = (x * calibration_offset[0], y * calibration_offset[1])\n",
    "        for corner in tag_corners:\n",
    "            truepoints.append([origin[0] + corner[0], origin[1] + corner[1], 0])\n",
    "\n",
    "\n",
    "xgrid = np.array([p[0] for p in truepoints])\n",
    "ygrid = np.array([p[1] for p in truepoints])\n",
    "zgrid = np.array([p[2] for p in truepoints])\n",
    "\n",
    "opoints = np.dstack((xgrid, ygrid, zgrid)).reshape((-1, 1, 3)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded testimages/cal2.jpg of size 1080x1920\n",
      "could not find all apriltags\n",
      "loaded testimages/cal3.jpg of size 1080x1920\n",
      "loaded testimages/cal4.jpg of size 1080x1920\n",
      "loaded testimages/cal5.jpg of size 1080x1920\n",
      "could not find all apriltags\n",
      "loaded testimages/cal6.jpg of size 1080x1920\n",
      "loaded testimages/cal7.jpg of size 1080x1920\n",
      "loaded testimages/cal8.jpg of size 1080x1920\n",
      "loaded testimages/cal9.jpg of size 1080x1920\n",
      "could not find all apriltags\n",
      "loaded testimages/cal10.jpg of size 1080x1920\n",
      "loaded testimages/cal11.jpg of size 1080x1920\n",
      "could not find all apriltags\n",
      "loaded testimages/cal12.jpg of size 1080x1920\n",
      "loaded testimages/cal13.jpg of size 1080x1920\n",
      "loaded testimages/cal14.jpg of size 1080x1920\n",
      "could not find all apriltags\n",
      "loaded testimages/cal15.jpg of size 1080x1920\n",
      "loaded testimages/cal16.jpg of size 1080x1920\n",
      "44/45 testimages/cal2.jpg\n",
      "39/45 testimages/cal5.jpg\n",
      "46/45 testimages/cal9.jpg\n",
      "46/45 testimages/cal11.jpg\n",
      "46/45 testimages/cal14.jpg\n",
      "Used 10/15 images.  See above for list of unusable images.\n",
      "[[867.17145309   0.         518.26941157]\n",
      " [  0.           7.27007783 910.77938444]\n",
      " [  0.           0.           1.        ]]\n",
      "[[0. 0. 0. 0. 0.]]\n",
      "\n",
      "all units below measured in pixels:\n",
      "  fx = 867.1714530943214\n",
      "  fy = 7.2700778250832485\n",
      "  cx = 518.2694115721059\n",
      "  cy = 910.7793844438535\n",
      "\n",
      "pastable into Python:\n",
      "  fx, fy, cx, cy = (867.1714530943214, 7.2700778250832485, 518.2694115721059, 910.7793844438535)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imagesize = None\n",
    "\n",
    "truepoints = []\n",
    "ipoints = []\n",
    "\n",
    "usableImageCount = 0\n",
    "unusable = []\n",
    "\n",
    "for filename in calibration_images:\n",
    "    rgb = cv2.imread(filename)\n",
    "\n",
    "    if rgb is None:\n",
    "        print(\"warning: error opening {}, skipping\".format(filename))\n",
    "        continue\n",
    "\n",
    "    cursize = (rgb.shape[1], rgb.shape[0])\n",
    "\n",
    "    if imagesize is None:\n",
    "        imagesize = cursize\n",
    "    else:\n",
    "        assert imagesize == cursize\n",
    "\n",
    "    print(\"loaded \" + filename + \" of size {}x{}\".format(*imagesize))\n",
    "\n",
    "    if len(rgb.shape) == 3:\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = rgb\n",
    "\n",
    "    results = detector.detect(gray)\n",
    "    if len(results) == tag_count:\n",
    "        usableImageCount += 1\n",
    "        truepoints.append(opoints)\n",
    "        foundpoints = []\n",
    "        for tag in results:\n",
    "            corners = tag.corners\n",
    "            for c in corners:\n",
    "                foundpoints.append([c])\n",
    "\n",
    "        ipoints.append(foundpoints)\n",
    "    else:\n",
    "        print(\"could not find all apriltags\")\n",
    "        unusable.append(str(len(results)) + \"/\" + str(tag_count) + \" \" + filename)\n",
    "\n",
    "\n",
    "flags = (\n",
    "    cv2.CALIB_ZERO_TANGENT_DIST\n",
    "    | cv2.CALIB_FIX_K1\n",
    "    | cv2.CALIB_FIX_K2\n",
    "    | cv2.CALIB_FIX_K3\n",
    "    | cv2.CALIB_FIX_K4\n",
    "    | cv2.CALIB_FIX_K5\n",
    "    | cv2.CALIB_FIX_K6\n",
    ")\n",
    "truepoints = np.array(truepoints, dtype=np.float32)\n",
    "# truepoints = truepoints.reshape((-1,1,3)).astype(np.float32)\n",
    "\n",
    "ipoints = np.array(ipoints, dtype=np.float32)\n",
    "# ipoints = ipoints.reshape((-1,1,3)).astype(np.float32)\n",
    "\n",
    "# print(truepoints.shape)\n",
    "# print(ipoints.shape)\n",
    "\n",
    "for el in unusable:\n",
    "    print(el)\n",
    "print(\n",
    "    f\"Used {usableImageCount}/{len(calibration_images)} images.  See above for list of unusable images.\"\n",
    ")\n",
    "\n",
    "retval, K, dcoeffs, rvecs, tvecs = cv2.calibrateCamera(\n",
    "    truepoints,\n",
    "    ipoints,\n",
    "    imagesize,\n",
    "    cameraMatrix=None,\n",
    "    distCoeffs=None,\n",
    "    flags=flags,\n",
    ")\n",
    "print(K)\n",
    "print(dcoeffs)\n",
    "fx = K[0, 0]\n",
    "fy = K[1, 1]\n",
    "cx = K[0, 2]\n",
    "cy = K[1, 2]\n",
    "\n",
    "params = (fx, fy, cx, cy)\n",
    "\n",
    "print()\n",
    "print(\"all units below measured in pixels:\")\n",
    "print(\"  fx = {}\".format(K[0, 0]))\n",
    "print(\"  fy = {}\".format(K[1, 1]))\n",
    "print(\"  cx = {}\".format(K[0, 2]))\n",
    "print(\"  cy = {}\".format(K[1, 2]))\n",
    "print()\n",
    "print(\"pastable into Python:\")\n",
    "print(\"  fx, fy, cx, cy = {}\".format(repr(params)))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given 4 points in one frame, and their corresponding points in another, calculate the transformation matrix between the frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "import marthabot.utils.realsense_utils as rsu \n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "pipe = rsu.get_pipe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_size = (6,9)\n",
    "# termination criteria\n",
    "criteria = (cv.TERM_CRITERIA_EPS + cv.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((grid_size[0]*grid_size[1],3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:grid_size[0],0:grid_size[1]].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "pret, pmtx, pdist, prvecs, ptvecs = 0,0,0,0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting more images to improve estimates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41717426 0.         1.35858572]\n",
      " [0.         0.11615335 0.30910743]\n",
      " [0.         0.         0.        ]]\n",
      "Getting more images to improve estimates\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-682ae3c56840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrateCamera\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;31m# print(mtx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# print(dist)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    print(\"Getting more images to improve estimates\")\n",
    "    i = 0\n",
    "    while i < 5:\n",
    "        frame, _ = rsu.get_frame(pipe)\n",
    "\n",
    "        # Find the chess board corners\n",
    "        ret, corners = cv.findChessboardCorners(frame, (grid_size[0],grid_size[1]), None)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if ret == True:\n",
    "            i += 1\n",
    "            objpoints.append(objp)\n",
    "            corners2 = cv.cornerSubPix(frame,corners, (11,11), (-1,-1), criteria)\n",
    "            imgpoints.append(corners2)\n",
    "            cv.drawChessboardCorners(frame, (grid_size[0],grid_size[1]), corners2, ret)\n",
    "        cv.imwrite(\"output.jpg\",frame)\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv.calibrateCamera(objpoints, imgpoints, frame.shape[::-1], None, None)\n",
    "    # print(mtx)\n",
    "    # print(dist)\n",
    "    evaluatat = (cv.absdiff(mtx,pmtx)) \n",
    "    print(evaluatat)\n",
    "    if (evaluatat < 1).all():\n",
    "        break\n",
    "    else:\n",
    "        pret, pmtx, pdist, prvecs, ptvecs = ret, mtx, dist, rvecs, tvecs\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720 1280\n",
      "[[[135 135 135]\n",
      "  [137 137 137]\n",
      "  [138 138 138]\n",
      "  ...\n",
      "  [136 136 136]\n",
      "  [136 136 136]\n",
      "  [137 137 137]]\n",
      "\n",
      " [[137 137 137]\n",
      "  [138 138 138]\n",
      "  [137 137 137]\n",
      "  ...\n",
      "  [136 136 136]\n",
      "  [135 135 135]\n",
      "  [136 136 136]]\n",
      "\n",
      " [[136 136 136]\n",
      "  [136 136 136]\n",
      "  [135 135 135]\n",
      "  ...\n",
      "  [137 137 137]\n",
      "  [136 136 136]\n",
      "  [137 137 137]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 14  14  14]\n",
      "  [ 13  13  13]\n",
      "  [ 13  13  13]\n",
      "  ...\n",
      "  [ 42  42  42]\n",
      "  [ 44  44  44]\n",
      "  [ 46  46  46]]\n",
      "\n",
      " [[ 16  16  16]\n",
      "  [ 14  14  14]\n",
      "  [ 13  13  13]\n",
      "  ...\n",
      "  [ 41  41  41]\n",
      "  [ 43  43  43]\n",
      "  [ 45  45  45]]\n",
      "\n",
      " [[ 17  17  17]\n",
      "  [ 14  14  14]\n",
      "  [ 13  13  13]\n",
      "  ...\n",
      "  [ 41  41  41]\n",
      "  [ 42  42  42]\n",
      "  [ 43  43  43]]]\n",
      "(720, 1280, 3)\n",
      "(720, 1280, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('output.jpg')\n",
    "cv2.imwrite('pre.png', img)\n",
    "h, w = img.shape[:2]\n",
    "print(h,w)\n",
    "newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 0, (w,h))\n",
    "# undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newcameramtx)\n",
    "# print(dst)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "# dst = dst[y:y+h, x:x+w]\n",
    "print(dst.shape)\n",
    "print(img.shape)\n",
    "cv2.imwrite('post.png', dst)\n",
    "diff = cv2.absdiff(img,dst)\n",
    "cv2.imwrite('diff.png', diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[945. 370.   0.   1.]\n",
      " [895. 370.   0.   1.]\n",
      " [200. 200.   0.   1.]\n",
      " [300. 200.   0.   1.]]\n",
      "[[  0.35725949  -0.37293477   0.07769117  -0.06201589]\n",
      " [ -0.93323486   0.97881147  -0.20215402   0.15657741]\n",
      " [  1.82705603  -1.91234687   0.41928219  -0.33399135]\n",
      " [-22.70687854  23.117348    -5.87742858   6.46695912]]\n",
      "[[ 1.00000000e+00 -3.55271368e-15  8.88178420e-16  1.77635684e-15]\n",
      " [ 6.39488462e-14  1.00000000e+00  7.99360578e-15  0.00000000e+00]\n",
      " [ 1.42108547e-14  3.55271368e-15  1.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.48689958e-14  4.44089210e-15  1.00000000e+00]]\n",
      "[[ -30.39355841   32.85423475   -7.25625921    5.79558286]\n",
      " [ -48.25653302   51.50097329  -11.14081772    8.89637746]\n",
      " [-137.90195308  144.29268848  -30.76999805   25.37926266]\n",
      " [-102.17600386  106.99921141  -23.00088103   19.17767347]]\n",
      "-7.256259205026308\n",
      "(132.77201238037787, nan, -160.09632231621543)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in arcsin\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def rt2orientation(rt):\n",
    "    r13 = rt[0,2]\n",
    "    print(r13)\n",
    "    r23 = rt[1,2]\n",
    "    r33 = rt[2,2]\n",
    "\n",
    "    r11 = rt[0,0]\n",
    "    r12 = rt[0,1]\n",
    "\n",
    "    ry = np.arcsin(-r13) * 180 / np.pi\n",
    "    rz = np.arctan2(r12,r11) * 180 / np.pi\n",
    "    rx = np.arctan2(r23,r33) * 180 / np.pi\n",
    "    return (rz,ry,rx)\n",
    "\n",
    "calc1 = np.array([ 942.763,  373.522,  19.419,  1.000])\n",
    "real1 = np.array([ 945.000,  370.000,  0.000,  1.000])\n",
    "calc2 = np.array([ 893.323,  374.951,  29.269,  1.000])\n",
    "real2 = np.array([ 895.000,  370.000,  0.000,  1.000])\n",
    "calc3 = np.array([ 215.177,  215.715,  80.537,  1.000])\n",
    "real3 = np.array([ 200.000,  200.000,  0.000,  1.000])\n",
    "calc4 = np.array([ 312.455,  167.234,  36.752,  1.000])\n",
    "real4 = np.array([ 300.000,  200.000,  0.000,  1.000])\n",
    "# calc4 = np.array([ 843.701,  382.801,  35.101,  1.000])\n",
    "# real4 = np.array([ 845.000,  370.000,  0.000,  1.000])\n",
    "\n",
    "u = np.array([calc1,calc2,calc3,calc4]).reshape(4,4)\n",
    "v = np.array([real1,real2,real3,real4]).reshape(4,4)\n",
    "\n",
    "# print(u)\n",
    "print(v)\n",
    "print(np.linalg.inv(u))\n",
    "print(u @ np.linalg.inv(u))\n",
    "t = v @ np.linalg.inv(u)\n",
    "\n",
    "print(t)\n",
    "print(rt2orientation(t))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
